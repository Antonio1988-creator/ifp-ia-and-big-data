{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh6r3fMnEQR7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "038ebe81"
      },
      "source": [
        "## **Bloque 1: Matrices y operaciones fundamentales**En este bloque, repasaremos y aplicaremos los conceptos básicos de matrices, que son la base para entender la regresión lineal en un contexto más avanzado. Presta atención a la notación y a las reglas de cada operación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3059274d"
      },
      "source": [
        "### **Ejercicio 1: Definición de matrices y dimensiones** Dadas las siguientes matrices:$$ A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\end{pmatrix} \\quad B = \\begin{pmatrix} 7 & 8 & 9 \\\\ 10 & 11 & 12 \\end{pmatrix} $$a) Define formalmente cada matriz (número de filas x número de columnas).\n",
        "b) Identifica el elemento $A_{2,1}$ y $B_{1,3}$.\n",
        "\n",
        "c) ¿Es posible sumar $A+B$? Justifica tu respuesta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a491738"
      },
      "source": [
        "### **Ejercicio 2: Suma y resta de matrices** dadas las matrices:$$ C = \\begin{pmatrix} 1 & 5 \\\\ 2 & 6 \\end{pmatrix} \\quad D = \\begin{pmatrix} 3 & 7 \\\\ 4 & 8 \\end{pmatrix} $$a) Calcula la suma $C + D$ .\n",
        "b) Calcula la resta $C - D$.\n",
        "\n",
        "c) Explica las condiciones necesarias para poder sumar o restar dos matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c2d529e"
      },
      "source": [
        "### **Ejercicio 3: Multiplicación por un escalar** dada la matriz: $E = \\begin{pmatrix} 1 & 0 & 3 \\\\ 2 & 1 & 4 \\end{pmatrix}$ y el escalar $\\alpha = 3$:\n",
        "a) Calcula el producto $\\alpha E $.\n",
        "\n",
        "b) Explica qué ocurre con las dimensiones de la matriz al multiplicarla por un escalar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "403a4c24"
      },
      "source": [
        "### **Ejercicio 4: Multiplicación de matrices** dadas las matrices:$$ F = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\quad G = \\begin{pmatrix} 5 & 6 \\\\ 7 & 8 \\end{pmatrix}$$\n",
        "\n",
        "a) Calcula el producto $F G$.\n",
        "\n",
        "b) ¿El producto $G F$ daría el mismo resultado? ¿Por qué sí o por qué no?\n",
        "\n",
        "c) Explica las condiciones necesarias para poder multiplicar dos matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5768ba3"
      },
      "source": [
        "### **Ejercicio 5: Matriz transpuesta** dada la matriz $H = \\begin{pmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{pmatrix}$:\n",
        "\n",
        "a) Calcula la transpuesta de $H$, denotada como $H^T$.\n",
        "\n",
        "b) Si una matriz es de dimensión $m \\times n$, ¿qué dimensión tendrá su transpuesta?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bae4e976"
      },
      "source": [
        "## **Bloque 2: Conceptos estadísticos para evaluar un modelo**. En este bloque, nos centraremos en las métricas estadísticas clave que nos permitirán entender y evaluar la calidad de un modelo de regresión. Estos conceptos son fundamentales para comprender cómo se mide el 'ajuste' de nuestro modelo a los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98e49b99"
      },
      "source": [
        "### **Ejercicio 6: Media, varianza y desviación estándar** dado el siguiente conjunto de datos de una variable $X = [2, 4, 4, 5, 6, 7, 9]$:\n",
        "\n",
        "a) Calcula la media (promedio) de $X$.\n",
        "\n",
        "b) Calcula la varianza de $X$.\n",
        "\n",
        "c) Calcula la desviación estándar de $X$.d) Explica brevemente qué representan la varianza y la desviación estándar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5bd8575"
      },
      "source": [
        "### **Ejercicio 7: Covarianza** dados los siguientes conjuntos de datos para dos variables $X$ e $Y$:$$ X = [1, 2, 3, 4, 5] \\quad Y = [2, 4, 5, 4, 5] $$\n",
        "\n",
        "a) Calcula la covarianza entre $X$ e $Y$.\n",
        "\n",
        "b) ¿Qué indica un valor de covarianza positivo, negativo o cercano a cero?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9e8faad"
      },
      "source": [
        "### **Ejercicio 8: Coeficiente de correlación de Pearson** usando los mismos datos del Ejercicio 7 ($X = [1, 2, 3, 4, 5]$ y $Y = [2, 4, 5, 4, 5]$):\n",
        "\n",
        "a) Calcula el coeficiente de correlación de Pearson ($r$).\n",
        "\n",
        "b) ¿Qué rango de valores puede tomar el coeficiente de correlación? ¿Qué significa un valor cercano a 1, a -1 o a 0?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "121ef386"
      },
      "source": [
        "## **Bloque 3: Regresión lineal y método OLS**. En este bloque, profundizaremos en el corazón de la regresión lineal, entendiendo cómo se construye un modelo y cómo el método de Mínimos Cuadrados Ordinarios (OLS) nos permite encontrar la 'mejor' línea de ajuste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a82acea1"
      },
      "source": [
        "### **Ejercicio 9: Ecuación de la recta de regresión**. La ecuación de una regresión lineal simple es $y = \\beta_0 + \\beta_1 x + \\epsilon$, donde $\\beta_0$ es la ordenada al origen, $\\beta_1$ es la pendiente y $\\epsilon$ es el término de error.\n",
        "a) Explica qué representa cada componente de esta ecuación en el contexto de un modelo que busca predecir una variable $y$ a partir de una variable $x$.\n",
        "\n",
        "b) ¿Cuál es el objetivo principal del método OLS al estimar $\\beta_0$ y $\\beta_1$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe78578d"
      },
      "source": [
        "### **Ejercicio 10: Suma de Cuadrados (SS) para R²**: Considera un modelo de regresión. Para calcular el R², necesitamos tres tipos de sumas de cuadrados: Suma Total de Cuadrados ($SS_{total}$), Suma de Cuadrados de la Regresión ($SS_{regresión}$ o $SS_{explicada}$) y Suma de Cuadrados Residual ($SS_{residual}$ o $SS_{error}$).\n",
        "\n",
        "a) Define cada una de estas sumas de cuadrados en palabras y con sus fórmulas matemáticas.\n",
        "\n",
        "b) ¿Cómo se relacionan estas tres sumas de cuadrados entre sí?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "745b548c"
      },
      "source": [
        "### **Ejercicio 11: Coeficiente de Determinación (R²)** Una vez que hemos calculado las Sumas de Cuadrados:\n",
        "\n",
        "a) Escribe la fórmula del coeficiente de determinación R² en términos de las Sumas de Cuadrados.\n",
        "\n",
        "b) Explica el significado de R². ¿Qué indica un R² cercano a 1, a 0 o incluso negativo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72e559e7"
      },
      "source": [
        "## **Bloque 4: Aplicación en Python con NumPy**:  \n",
        "En este bloque, llevaremos los conceptos aprendidos a la práctica utilizando la biblioteca NumPy de Python. Podrás elegir entre resolver 'a mano' o usar Python para los cálculos. Si usas Python, recuerda incluir el código, la salida y una breve explicación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f95ec07"
      },
      "source": [
        "### **Ejercicio 12: Preparación de datos y adición de intercepto** dadas las siguientes observaciones para una variable independiente $X$ y una variable dependiente $Y$:$$ X = [1, 2, 3, 4, 5] \\\\ Y = [2, 3.5, 4.5, 5, 6] $$\n",
        "\n",
        "a) Crea las matrices correspondientes a $X$ y $Y$ (o vectores) en NumPy si decides usar Python.\n",
        "\n",
        "b) Para aplicar el método OLS en su forma matricial, necesitamos añadir una columna de unos a la matriz de variables independientes para representar el término de intercepto ($\\beta_0$). Muestra cómo construir la matriz de diseño $X_{diseño}$ (o $X$) con esta columna de unos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96b6caeb"
      },
      "source": [
        "### **Ejercicio 13: Cálculo de coeficientes OLS ($\\beta$)** utilizando la matriz de diseño $X_{diseño}$ y el vector $Y$ del Ejercicio 12, calcula los coeficientes de regresión $\\beta = (\\beta_0, \\beta_1)$ usando la fórmula matricial OLS:$$ \\hat{\\beta} = (X^T X)^{-1} X^T Y $$Puedes realizar este cálculo 'a mano' o utilizando NumPy para las operaciones matriciales (transpuesta, inversión, multiplicación)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6792fbc3"
      },
      "source": [
        "### **Ejercicio 14: Predicciones y residuos** con los coeficientes $\\hat{\\beta}$ obtenidos en el Ejercicio 13:\n",
        "a) Calcula los valores predichos $\\hat{Y}$ para cada observación utilizando $X_{diseño}$ y $\\hat{\\beta}$ ($ \\hat{Y} = X_{diseño} \\hat{\\beta} $).\n",
        "\n",
        "b) Calcula los residuos ($e_i = Y_i - \\hat{Y}_i$) para cada observación.\n",
        "\n",
        "c) ¿Qué esperas que sumen los residuos en un modelo OLS bien ajustado?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f665829"
      },
      "source": [
        "### **Ejercicio 15: Cálculo del R²**Utilizando los valores $Y$ observados y los valores $\\hat{Y}$ predichos del Ejercicio 14, así como la media de $Y$:\n",
        "\n",
        "a) Calcula la Suma Total de Cuadrados ($SS_{total}$).\n",
        "\n",
        "b) Calcula la Suma de Cuadrados de la Regresión ($SS_{regresión}$).\n",
        "\n",
        "c) Calcula la Suma de Cuadrados Residual ($SS_{residual}$).\n",
        "\n",
        "d) Finalmente, calcula el coeficiente de determinación R².\n",
        "\n",
        "e) Interpreta el valor de R² obtenido para este modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c77965ed"
      },
      "source": [
        "---# **Respuestas a los Ejercicios**---## **Bloque 1: Matrices y operaciones fundamentales**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f220e099"
      },
      "source": [
        "### **Ejercicio 1: Definición de matrices y dimensiones**Dadas las siguientes matrices:$$ A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\end{pmatrix} \\quad B = \\begin{pmatrix} 7 & 8 & 9 \\\\ 10 & 11 & 12 \\end{pmatrix} $$a) Define formalmente cada matriz (número de filas x número de columnas).b) Identifica el elemento $A_{2,1}$ y $B_{1,3}$.c) ¿Es posible sumar $A+B$? Justifica tu respuesta.**Respuesta:**a) **Matriz A:** Tiene 3 filas y 2 columnas. Por lo tanto, su dimensión es $3 \\times 2$.**Matriz B:** Tiene 2 filas y 3 columnas. Por lo tanto, su dimensión es $2 \\times 3$.b) El elemento $A_{2,1}$ se refiere al elemento en la fila 2, columna 1 de la matriz A. En este caso, $A_{2,1} = 3$.El elemento $B_{1,3}$ se refiere al elemento en la fila 1, columna 3 de la matriz B. En este caso, $B_{1,3} = 9$.c) **No es posible sumar $A+B$**. La condición necesaria para sumar o restar dos matrices es que ambas deben tener las mismas dimensiones (el mismo número de filas y el mismo número de columnas). Dado que A es de $3 \\times 2$ y B es de $2 \\times 3$, sus dimensiones son diferentes, lo que impide la suma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "699568ba"
      },
      "source": [
        "### **Ejercicio 2: Suma y resta de matrices**Dadas las matrices:$$ C = \\begin{pmatrix} 1 & 5 \\\\ 2 & 6 \\end{pmatrix} \\quad D = \\begin{pmatrix} 3 & 7 \\\\ 4 & 8 \\end{pmatrix} $$a) Calcula la suma $C + D$.b) Calcula la resta $C - D$.c) Explica las condiciones necesarias para poder sumar o restar dos matrices.**Respuesta:**a) **Suma $C + D$:**Para sumar matrices, se suman los elementos correspondientes en la misma posición:$$ C + D = \\begin{pmatrix} 1+3 & 5+7 \\\\ 2+4 & 6+8 \\end{pmatrix} = \\begin{pmatrix} 4 & 12 \\\\ 6 & 14 \\end{pmatrix} $$b) **Resta $C - D$:**Para restar matrices, se restan los elementos correspondientes en la misma posición:$$ C - D = \\begin{pmatrix} 1-3 & 5-7 \\\\ 2-4 & 6-8 \\end{pmatrix} = \\begin{pmatrix} -2 & -2 \\\\ -2 & -2 \\end{pmatrix} $$c) **Condiciones necesarias para sumar o restar dos matrices:**Para poder sumar o restar dos matrices, estas deben tener **exactamente las mismas dimensiones**. Esto significa que deben tener el mismo número de filas y el mismo número de columnas. Si las dimensiones son diferentes, la operación no está definida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7edccc7"
      },
      "source": [
        "### **Ejercicio 3: Multiplicación por un escalar**Dada la matriz $E = \\begin{pmatrix} 1 & 0 & 3 \\\\ 2 & 1 & 4 \\end{pmatrix}$ y el escalar $\\alpha = 3$:a) Calcula el producto $\\alpha E$.b) Explica qué ocurre con las dimensiones de la matriz al multiplicarla por un escalar.**Respuesta:**a) **Producto $\\alpha E$:**Para multiplicar una matriz por un escalar, se multiplica cada elemento de la matriz por el escalar:$$ \\alpha E = 3 \\begin{pmatrix} 1 & 0 & 3 \\\\ 2 & 1 & 4 \\end{pmatrix} = \\begin{pmatrix} 3 \\times 1 & 3 \\times 0 & 3 \\times 3 \\\\ 3 \\times 2 & 3 \\times 1 & 3 \\times 4 \\end{pmatrix} = \\begin{pmatrix} 3 & 0 & 9 \\\\ 6 & 3 & 12 \\end{pmatrix} $$b) **Efecto en las dimensiones:**Al multiplicar una matriz por un escalar, **las dimensiones de la matriz no cambian**. Cada elemento se escala, pero la estructura de filas y columnas permanece idéntica. Si $E$ es de $m \\times n$, $\\alpha E$ seguirá siendo de $m \\times n$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84cd5de9"
      },
      "source": [
        "### **Ejercicio 4: Multiplicación de matrices**Dadas las matrices:$$ F = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix} \\quad G = \\begin{pmatrix} 5 & 6 \\\\ 7 & 8 \\end{pmatrix} $$a) Calcula el producto $F G$.b) ¿El producto $G F$ daría el mismo resultado? ¿Por qué sí o por qué no?c) Explica las condiciones necesarias para poder multiplicar dos matrices.**Respuesta:**a) **Producto $F G$:**Para multiplicar matrices, el elemento en la fila $i$, columna $j$ del producto se obtiene multiplicando los elementos de la fila $i$ de la primera matriz por los elementos de la columna $j$ de la segunda matriz y sumando los resultados:$$ F G = \\begin{pmatrix} (1 \\times 5) + (2 \\times 7) & (1 \\times 6) + (2 \\times 8) \\\\ (3 \\times 5) + (4 \\times 7) & (3 \\times 6) + (4 \\times 8) \\end{pmatrix} $$$$ F G = \\begin{pmatrix} 5 + 14 & 6 + 16 \\\\ 15 + 28 & 18 + 32 \\end{pmatrix} = \\begin{pmatrix} 19 & 22 \\\\ 43 & 50 \\end{pmatrix} $$b) **¿$G F$ daría el mismo resultado?**No, el producto $G F$ **generalmente no daría el mismo resultado** que $F G$. Esto se debe a que la multiplicación de matrices **no es conmutativa**, es decir, el orden de los factores altera el producto. Aunque en este caso ambas matrices son cuadradas de $2 \\times 2$ y la multiplicación en ambos sentidos es posible, el resultado numérico será diferente.Calculemos $G F$ para verificar:$$ G F = \\begin{pmatrix} (5 \\times 1) + (6 \\times 3) & (5 \\times 2) + (6 \\times 4) \\\\ (7 \\times 1) + (8 \\times 3) & (7 \\times 2) + (8 \\times 4) \\end{pmatrix} $$$$ G F = \\begin{pmatrix} 5 + 18 & 10 + 24 \\\\ 7 + 24 & 14 + 32 \\end{pmatrix} = \\begin{pmatrix} 23 & 34 \\\\ 31 & 46 \\end{pmatrix} $$Como se puede observar, $F G \\neq G F$.c) **Condiciones necesarias para poder multiplicar dos matrices:**Para poder multiplicar dos matrices $A$ y $B$ (para obtener $A B$), el **número de columnas de la primera matriz ($A$) debe ser igual al número de filas de la segunda matriz ($B$)**.Si $A$ es una matriz de dimensión $m \\times n$ y $B$ es una matriz de dimensión $n \\times p$, entonces el producto $A B$ será una matriz de dimensión $m \\times p$. Si esta condición no se cumple, la multiplicación no es posible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b8e73f0"
      },
      "source": [
        "### **Ejercicio 5: Matriz transpuesta**Dada la matriz $H = \\begin{pmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{pmatrix}$:a) Calcula la transpuesta de $H$, denotada como $H^T$.b) Si una matriz es de dimensión $m \\times n$, ¿qué dimensión tendrá su transpuesta?**Respuesta:**a) **Transpuesta de $H$ ($H^T$):**La transpuesta de una matriz se obtiene intercambiando sus filas por sus columnas (o sus columnas por sus filas).$$ H^T = \\begin{pmatrix} 1 & 4 \\\\ 2 & 5 \\\\ 3 & 6 \\end{pmatrix} $$b) **Dimensión de la transpuesta:**Si una matriz original tiene una dimensión de $m \\times n$ (m filas y n columnas), su transpuesta tendrá una dimensión de **$n \\times m$** (n filas y m columnas).En este caso, $H$ es de $2 \\times 3$, por lo que $H^T$ es de $3 \\times 2$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29b196b6"
      },
      "source": [
        "## **Bloque 2: Conceptos estadísticos para evaluar un modelo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af6a4bde"
      },
      "source": [
        "### **Ejercicio 6: Media, varianza y desviación estándar**Dado el siguiente conjunto de datos de una variable $X = [2, 4, 4, 5, 6, 7, 9]$:a) Calcula la media (promedio) de $X$.b) Calcula la varianza de $X$.c) Calcula la desviación estándar de $X$.d) Explica brevemente qué representan la varianza y la desviación estándar.**Respuesta:**Primero, listamos los datos y el número de observaciones ($n$):$X = [2, 4, 4, 5, 6, 7, 9]$$n = 7$a) **Media (promedio) de $X$ ($\\bar{X}$):**La media se calcula sumando todos los valores y dividiendo por el número total de valores:$$ \\bar{X} = \\frac{\\sum X_i}{n} = \\frac{2+4+4+5+6+7+9}{7} = \\frac{37}{7} \\approx 5.2857 $$b) **Varianza de $X$ ($\\sigma^2$ o $s^2$):**La varianza mide la dispersión de los datos alrededor de la media. Se calcula como el promedio de los cuadrados de las diferencias entre cada valor y la media. (Usaremos la fórmula poblacional o muestral dividiendo por n-1, si no se especifica, se suele usar la muestral para estimación):$$ s^2 = \\frac{\\sum (X_i - \\bar{X})^2}{n-1} $$Calculamos las diferencias y sus cuadrados:($2 - 5.2857)^2 = (-3.2857)^2 \\approx 10.7958$($4 - 5.2857)^2 = (-1.2857)^2 \\approx 1.6530$($4 - 5.2857)^2 = (-1.2857)^2 \\approx 1.6530$($5 - 5.2857)^2 = (-0.2857)^2 \\approx 0.0816$($6 - 5.2857)^2 = (0.7143)^2 \\approx 0.5102$($7 - 5.2857)^2 = (1.7143)^2 \\approx 2.9388$($9 - 5.2857)^2 = (3.7143)^2 \\approx 13.7960$Suma de los cuadrados de las diferencias $\\sum (X_i - \\bar{X})^2 \\approx 10.7958 + 1.6530 + 1.6530 + 0.0816 + 0.5102 + 2.9388 + 13.7960 = 31.4284$$ s^2 = \\frac{31.4284}{7-1} = \\frac{31.4284}{6} \\approx 5.2381 $$c) **Desviación estándar de $X$ ($s$):**La desviación estándar es la raíz cuadrada de la varianza:$$ s = \\sqrt{s^2} = \\sqrt{5.2381} \\approx 2.2887 $$d) **Representación de la varianza y la desviación estándar:**-   **Varianza:** Mide la **dispersión o variabilidad promedio de los datos** con respecto a la media. Un valor alto indica que los datos están muy dispersos, mientras que un valor bajo indica que los datos están más agrupados cerca de la media. Las unidades de la varianza son las unidades de los datos al cuadrado, lo que a menudo dificulta su interpretación directa.-   **Desviación estándar:** Es la raíz cuadrada positiva de la varianza. Es una medida de dispersión **más interpretable** que la varianza porque sus unidades son las mismas que las de los datos originales. Nos dice, en promedio, **cuánto se desvían los datos individuales de la media**. Una desviación estándar grande indica una mayor variabilidad (los datos están más dispersos), y una pequeña indica que los datos están más concentrados alrededor de la media."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fd20914"
      },
      "source": [
        "### **Ejercicio 7: Covarianza**Dados los siguientes conjuntos de datos para dos variables $X$ e $Y$:$$ X = [1, 2, 3, 4, 5] \\quad Y = [2, 4, 5, 4, 5] $$a) Calcula la covarianza entre $X$ e $Y$.b) ¿Qué indica un valor de covarianza positivo, negativo o cercano a cero?**Respuesta:**a) **Covarianza entre $X$ e $Y$ ($Cov(X, Y)$):**La covarianza mide el grado en que dos variables varían juntas. Primero necesitamos calcular las medias de $X$ y $Y$.**Paso 1: Calcular la media de $X$ ($\\bar{X}$) y la media de $Y$ ($\\bar{Y}$):**$$ \\bar{X} = \\frac{1+2+3+4+5}{5} = \\frac{15}{5} = 3 $$$$ \\bar{Y} = \\frac{2+4+5+4+5}{5} = \\frac{20}{5} = 4 $$**Paso 2: Calcular la suma de los productos de las desviaciones de cada punto con respecto a su media:**$$ Cov(X, Y) = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{n-1} $$Calculamos $(X_i - \\bar{X})$ y $(Y_i - \\bar{Y})$ para cada par:|$X_i$|$Y_i$|$(X_i - \\bar{X})$|$(Y_i - \\bar{Y})$|$(X_i - \\bar{X})(Y_i - \\bar{Y})$||---|---|---|---|---||1|2|$1-3 = -2$|$2-4 = -2$|$(-2) \\times (-2) = 4$||2|4|$2-3 = -1$|$4-4 = 0$|$(-1) \\times 0 = 0$||3|5|$3-3 = 0$|$5-4 = 1$|$0 \\times 1 = 0$||4|4|$4-3 = 1$|$4-4 = 0$|$1 \\times 0 = 0$||5|5|$5-3 = 2$|$5-4 = 1$|$2 \\times 1 = 2$|Suma de productos de desviaciones = $4 + 0 + 0 + 0 + 2 = 6$**Paso 3: Calcular la covarianza (usando $n-1$ para la muestra):**$$ Cov(X, Y) = \\frac{6}{5-1} = \\frac{6}{4} = 1.5 $$b) **Interpretación del valor de covarianza:**-   **Covarianza positiva ($>0$):** Indica que las dos variables tienden a moverse en la misma dirección. Si una variable aumenta, la otra tiende a aumentar; si una disminuye, la otra tiende a disminuir. En nuestro caso, $Cov(X, Y) = 1.5$ (positivo) sugiere una relación directa entre X e Y.-   **Covarianza negativa ($<0$):** Indica que las dos variables tienden a moverse en direcciones opuestas. Si una variable aumenta, la otra tiende a disminuir, y viceversa.-   **Covarianza cercana a cero ($\\approx 0$):** Sugiere que no hay una relación lineal fuerte entre las dos variables. Podrían ser independientes, o podría existir una relación no lineal que la covarianza no capta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76b1f99e"
      },
      "source": [
        "### **Ejercicio 8: Coeficiente de correlación de Pearson**Usando los mismos datos del Ejercicio 7 ($X = [1, 2, 3, 4, 5]$ y $Y = [2, 4, 5, 4, 5]$):a) Calcula el coeficiente de correlación de Pearson ($r$).b) ¿Qué rango de valores puede tomar el coeficiente de correlación? ¿Qué significa un valor cercano a 1, a -1 o a 0?**Respuesta:**a) **Coeficiente de correlación de Pearson ($r$):**El coeficiente de correlación de Pearson mide la fuerza y dirección de una relación lineal entre dos variables. Se calcula como:$$ r = \\frac{Cov(X, Y)}{s_X s_Y} $$Donde $Cov(X, Y)$ es la covarianza entre $X$ e $Y$, y $s_X$ y $s_Y$ son las desviaciones estándar de $X$ e $Y$, respectivamente.**Paso 1: Ya calculamos la covarianza en el Ejercicio 7:** $Cov(X, Y) = 1.5$.**Paso 2: Calcular las desviaciones estándar $s_X$ y $s_Y$:**Necesitamos la varianza de $X$ y $Y$. Ya tenemos $\\bar{X}=3$ y $\\bar{Y}=4$.**Para $X$:**$(1-3)^2 = 4$\n",
        "$(2-3)^2 = 1$\n",
        "$(3-3)^2 = 0$\n",
        "$(4-3)^2 = 1$\n",
        "$(5-3)^2 = 4$$\\sum (X_i - \\bar{X})^2 = 4+1+0+1+4 = 10$$ s_X^2 = \\frac{10}{5-1} = \\frac{10}{4} = 2.5 \\implies s_X = \\sqrt{2.5} \\approx 1.5811 $**Para $Y$:**$(2-4)^2 = 4$\n",
        "$(4-4)^2 = 0$\n",
        "$(5-4)^2 = 1$\n",
        "$(4-4)^2 = 0$\n",
        "$(5-4)^2 = 1$$\\sum (Y_i - \\bar{Y})^2 = 4+0+1+0+1 = 6$$ s_Y^2 = \\frac{6}{5-1} = \\frac{6}{4} = 1.5 \\implies s_Y = \\sqrt{1.5} \\approx 1.2247 $**Paso 3: Calcular $r$:**$$ r = \\frac{1.5}{1.5811 \\times 1.2247} = \\frac{1.5}{1.9365} \\approx 0.7746 $$b) **Rango de valores e interpretación:**El coeficiente de correlación de Pearson ($r$) siempre toma valores en el rango de **$-1$ a $1$** (inclusive, es decir, $[-1, 1]$).-   **Valor cercano a $1$:** Indica una **relación lineal positiva fuerte**. A medida que una variable aumenta, la otra tiende a aumentar de manera consistente y predecible. En nuestro caso, $r \\approx 0.7746$ sugiere una correlación positiva fuerte, pero no perfecta.-   **Valor cercano a $-1$:** Indica una **relación lineal negativa fuerte**. A medida que una variable aumenta, la otra tiende a disminuir de manera consistente y predecible.-   **Valor cercano a $0$:** Indica que **no hay una relación lineal significativa** entre las dos variables. Esto no significa que no haya ninguna relación (podría haber una relación no lineal), sino que la relación lineal es débil o inexistente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcc42e86"
      },
      "source": [
        "## **Bloque 3: Regresión lineal y método OLS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbe50430"
      },
      "source": [
        "### **Ejercicio 9: Ecuación de la recta de regresión**La ecuación de una regresión lineal simple es $y = \\beta_0 + \\beta_1 x + \\epsilon$, donde $\\beta_0$ es la ordenada al origen, $\\beta_1$ es la pendiente y $\\epsilon$ es el término de error.a) Explica qué representa cada componente de esta ecuación en el contexto de un modelo que busca predecir una variable $y$ a partir de una variable $x$.b) ¿Cuál es el objetivo principal del método OLS al estimar $\\beta_0$ y $\\beta_1$ ?**Respuesta:**a) **Representación de cada componente en $y = \\beta_0 + \\beta_1 x + \\epsilon$:**-   **$y$ (Variable Dependiente/Respuesta):** Es la variable que queremos predecir o explicar. Su valor depende de la variable independiente. Por ejemplo, si queremos predecir el precio de una casa, $y$ sería el precio.-   **$x$ (Variable Independiente/Predictora):** Es la variable que utilizamos para predecir o explicar $y$. Se asume que influye en el valor de $y$. Por ejemplo, si predecimos el precio de una casa, $x$ podría ser su tamaño en metros cuadrados.-   **$\\beta_0$ (Ordenada al Origen / Intercepto):** Representa el valor promedio de $y$ cuando $x$ es igual a cero. En algunos contextos tiene una interpretación directa (ej. salario base), en otros puede no tener sentido práctico o simplemente ajusta la línea de regresión. Es el punto donde la línea de regresión cruza el eje Y.-   **$\\beta_1$ (Pendiente / Coeficiente de Regresión):** Representa el cambio promedio en $y$ por cada unidad de cambio en $x$. Es la inclinación de la línea de regresión. Si $\\beta_1$ es positivo, $y$ tiende a aumentar cuando $x$ aumenta. Si es negativo, $y$ tiende a disminuir cuando $x$ aumenta.-   **$\\epsilon$ (Término de Error / Residuo):** Representa la parte de $y$ que no puede ser explicada por la relación lineal con $x$. Incluye todas las otras variables no observadas que influyen en $y$, así como la variabilidad aleatoria inherente a los datos. Es la diferencia entre el valor observado de $y$ y el valor predicho por el modelo para un $x$ dado.b) **Objetivo principal del método OLS al estimar $\\beta_0$ y $\\beta_1$:**El objetivo principal del método de **Mínimos Cuadrados Ordinarios (OLS)** es encontrar los valores de los coeficientes $\\beta_0$ y $\\beta_1$ (los parámetros del modelo) que **minimizan la suma de los cuadrados de los errores (residuos)**.En otras palabras, OLS busca la línea de regresión que mejor se ajusta a los datos, de tal manera que la distancia vertical al cuadrado entre cada punto de datos observado y la línea de regresión sea la menor posible. Al minimizar la suma de los errores al cuadrado, OLS asegura que los valores predichos por la línea estén lo más cerca posible de los valores reales de $y$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab4e7669"
      },
      "source": [
        "### **Ejercicio 10: Suma de Cuadrados (SS) para R²**Considera un modelo de regresión. Para calcular el R², necesitamos tres tipos de sumas de cuadrados: Suma Total de Cuadrados ($SS_{total}$), Suma de Cuadrados de la Regresión ($SS_{regresión}$ o $SS_{explicada}$) y Suma de Cuadrados Residual ($SS_{residual}$ o $SS_{error}$).a) Define cada una de estas sumas de cuadrados en palabras y con sus fórmulas matemáticas.b) ¿Cómo se relacionan estas tres sumas de cuadrados entre sí?**Respuesta:**a) **Definición y fórmulas de las Sumas de Cuadrados:**-   **Suma Total de Cuadrados ($SS_{total}$ o $SST$):**    *   **En palabras:** Mide la **variabilidad total** de la variable dependiente $Y$ con respecto a su media ($\\bar{Y}$). Representa la variación inherente en $Y$ que el modelo intenta explicar. Es una medida de cuánto varían los valores reales de $Y$ del promedio de $Y$.    *   **Fórmula:** $SS_{total} = \\sum (Y_i - \\bar{Y})^2$    Donde $Y_i$ son los valores observados de $Y$, y $\\bar{Y}$ es la media de $Y$.-   **Suma de Cuadrados de la Regresión ($SS_{regresión}$, $SS_{explicada}$ o $SSR$):**    *   **En palabras:** Mide la **variabilidad en $Y$ que es explicada por el modelo de regresión** (es decir, por la relación lineal con la variable $X$). Representa cuánto de la variación total de $Y$ es capturada por la línea de regresión.    *   **Fórmula:** $SS_{regresión} = \\sum (\\hat{Y}_i - \\bar{Y})^2$    Donde $\\hat{Y}_i$ son los valores predichos de $Y$ por el modelo, y $\\bar{Y}$ es la media de $Y$.-   **Suma de Cuadrados Residual ($SS_{residual}$, $SS_{error}$ o $SSE$):**    *   **En palabras:** Mide la **variabilidad en $Y$ que NO es explicada por el modelo de regresión**. Representa el error aleatorio o la varianza que el modelo no pudo capturar. Es la suma de los cuadrados de las diferencias entre los valores observados de $Y$ y los valores predichos por el modelo.    *   **Fórmula:** $SS_{residual} = \\sum (Y_i - \\hat{Y}_i)^2$    Donde $Y_i$ son los valores observados de $Y$, y $\\hat{Y}_i$ son los valores predichos de $Y$.b) **Relación entre las tres sumas de cuadrados:**Estas tres sumas de cuadrados están intrínsecamente relacionadas mediante la siguiente identidad:$$ SS_{total} = SS_{regresión} + SS_{residual} $$Esta relación significa que la variabilidad total en la variable dependiente ($Y$) se puede descomponer en dos partes: la variabilidad que es explicada por el modelo de regresión ($SS_{regresión}$) y la variabilidad que el modelo no logra explicar (el error o $SS_{residual}$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f2876d0"
      },
      "source": [
        "### **Ejercicio 11: Coeficiente de Determinación (R²)**Una vez que hemos calculado las Sumas de Cuadrados:a) Escribe la fórmula del coeficiente de determinación R² en términos de las Sumas de Cuadrados.b) Explica el significado de R². ¿Qué indica un R² cercano a 1, a 0 o incluso negativo?**Respuesta:**a) **Fórmula del coeficiente de determinación R²:**El coeficiente de determinación R² se puede expresar de varias formas usando las sumas de cuadrados:$$ R^2 = \\frac{SS_{regresión}}{SS_{total}} $$O, alternativamente, aprovechando la relación $SS_{total} = SS_{regresión} + SS_{residual}$:$$ R^2 = 1 - \\frac{SS_{residual}}{SS_{total}} $$b) **Significado de R² y su interpretación:**-   **Significado de R²:** El coeficiente de determinación R² (R-cuadrado) es una medida estadística que representa la **proporción de la varianza en la variable dependiente ($Y$) que puede ser predicha a partir de la(s) variable(s) independiente(s) ($X$)** en un modelo de regresión lineal. En términos más simples, indica **qué tan bien el modelo de regresión se ajusta a los datos**. Se expresa como un valor entre 0 y 1, o como un porcentaje (0% a 100%).-   **R² cercano a 1 (o 100%):** Indica que el modelo de regresión explica una **gran proporción de la variabilidad** de la variable dependiente. Esto sugiere un **excelente ajuste** del modelo a los datos, lo que significa que las variables independientes son muy buenas predictoras de la variable dependiente. Cuanto más cerca de 1, mejor es el ajuste.-   **R² cercano a 0 (o 0%):** Indica que el modelo de regresión explica una **muy pequeña (o ninguna) proporción de la variabilidad** de la variable dependiente. Esto sugiere un **ajuste pobre** del modelo a los datos, lo que significa que las variables independientes no son buenas predictoras de la variable dependiente, o que la relación lineal es muy débil.-   **R² negativo:** Un R² negativo es poco común en la regresión lineal simple estándar, pero puede ocurrir en modelos de regresión múltiple o cuando se utilizan modelos más complejos. Un R² negativo significa que el modelo que has ajustado se comporta **peor que un modelo que simplemente predice la media de la variable dependiente** para todos los puntos de datos. Es un indicador de que el modelo es muy deficiente y no se ajusta en absoluto a los datos, o que ha habido un error en el cálculo o en la especificación del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d9d6bbf"
      },
      "source": [
        "## **Bloque 4: Aplicación en Python con NumPy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b6922c3"
      },
      "source": [
        "### **Ejercicio 12: Preparación de datos y adición de intercepto**Dadas las siguientes observaciones para una variable independiente $X$ y una variable dependiente $Y$:$$ X = [1, 2, 3, 4, 5] \\\\ Y = [2, 3.5, 4.5, 5, 6] $$a) Crea las matrices correspondientes a $X$ y $Y$ (o vectores) en NumPy si decides usar Python.b) Para aplicar el método OLS en su forma matricial, necesitamos añadir una columna de unos a la matriz de variables independientes para representar el término de intercepto ($\\beta_0$). Muestra cómo construir la matriz de diseño $X_{diseño}$ (o $X$) con esta columna de unos.**Respuesta (con Python y NumPy):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bd3209f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# a) Crear vectores NumPy para X y Y\n",
        "X_original = np.array([1, 2, 3, 4, 5])\n",
        "Y = np.array([2, 3.5, 4.5, 5, 6])\n",
        "\n",
        "print(\"a) Vector X original:\")\n",
        "print(X_original)\n",
        "print(\"Vector Y:\")\n",
        "print(Y)\n",
        "\n",
        "# b) Construir la matriz de diseño X_diseño con una columna de unos\n",
        "# Reshape X_original para que sea una matriz de columna (n_observaciones, 1)\n",
        "X_reshaped = X_original.reshape(-1, 1)\n",
        "\n",
        "# Crear una columna de unos con el mismo número de filas que X_reshaped\n",
        "ones_column = np.ones((len(X_original), 1))\n",
        "\n",
        "# Concatenar la columna de unos y X_reshaped horizontalmente para formar X_diseño\n",
        "X_diseno = np.hstack((ones_column, X_reshaped))\n",
        "\n",
        "print(\"\\nb) Matriz de diseño X_diseño (con intercepto):\")\n",
        "print(X_diseno)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a57740e2"
      },
      "source": [
        "### **Ejercicio 13: Cálculo de coeficientes OLS ($\\beta$)**Utilizando la matriz de diseño $X_{diseño}$ y el vector $Y$ del Ejercicio 12, calcula los coeficientes de regresión $\\beta = (\\beta_0, \\beta_1)$ usando la fórmula matricial OLS:$$ \\hat{\\beta} = (X^T X)^{-1} X^T Y $$Puedes realizar este cálculo \\'a mano\\' o utilizando NumPy para las operaciones matriciales (transpuesta, inversión, multiplicación).**Respuesta (con Python y NumPy):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5da4614"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Recuperamos X_diseno y Y del Ejercicio 12\n",
        "# Si este código se ejecuta de forma independiente, tendrías que definirlos de nuevo:\n",
        "# X_original = np.array([1, 2, 3, 4, 5])\n",
        "# Y = np.array([2, 3.5, 4.5, 5, 6])\n",
        "# X_diseno = np.hstack((np.ones((len(X_original), 1)), X_original.reshape(-1, 1)))\n",
        "\n",
        "# a) Calcular (X^T X)\n",
        "X_transposed = X_diseno.T\n",
        "X_T_X = np.dot(X_transposed, X_diseno)\n",
        "print(\"a) X^T X:\")\n",
        "print(X_T_X)\n",
        "\n",
        "# b) Calcular (X^T X)^-1 (la inversa)\n",
        "X_T_X_inv = np.linalg.inv(X_T_X)\n",
        "print(\"\\nb) (X^T X)^-1:\")\n",
        "print(X_T_X_inv)\n",
        "\n",
        "# c) Calcular (X^T Y)\n",
        "X_T_Y = np.dot(X_transposed, Y)\n",
        "print(\"\\nc) X^T Y:\")\n",
        "print(X_T_Y)\n",
        "\n",
        "# d) Calcular los coeficientes beta (beta_hat)\n",
        "beta_hat = np.dot(X_T_X_inv, X_T_Y)\n",
        "\n",
        "# Los coeficientes son beta_0 (intercepto) y beta_1 (pendiente)\n",
        "beta_0 = beta_hat[0]\n",
        "beta_1 = beta_hat[1]\n",
        "\n",
        "print(\"\\nd) Coeficientes de regresión (beta_hat):\")\n",
        "print(f\"beta_0 (Intercepto): {beta_0:.4f}\")\n",
        "print(f\"beta_1 (Pendiente): {beta_1:.4f}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "098602eb"
      },
      "source": [
        "### **Ejercicio 14: Predicciones y residuos**Con los coeficientes $\\hat{\\beta}$ obtenidos en el Ejercicio 13:a) Calcula los valores predichos $\\hat{Y}$ para cada observación utilizando $X_{diseño}$ y $\\hat{\\beta}$ ($ \\hat{Y} = X_{diseño} \\hat{\\beta} $).b) Calcula los residuos ($e_i = Y_i - \\hat{Y}_i$) para cada observación.c) ¿Qué esperas que sumen los residuos en un modelo OLS bien ajustado?**Respuesta (con Python y NumPy):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94a8424f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Recuperamos X_diseno, Y y beta_hat del Ejercicio 13\n",
        "# Si este código se ejecuta de forma independiente, tendrías que definirlos de nuevo:\n",
        "# X_original = np.array([1, 2, 3, 4, 5])\n",
        "# Y = np.array([2, 3.5, 4.5, 5, 6])\n",
        "# X_diseno = np.hstack((np.ones((len(X_original), 1)), X_original.reshape(-1, 1))))\n",
        "# beta_hat = np.array([1.1, 0.9]) # Valores aproximados de un cálculo previo, usar los exactos\n",
        "\n",
        "# Para asegurar la continuidad, re-calculamos beta_hat si no está disponible\n",
        "X_original = np.array([1, 2, 3, 4, 5])\n",
        "Y = np.array([2, 3.5, 4.5, 5, 6])\n",
        "X_diseno = np.hstack((np.ones((len(X_original), 1)), X_original.reshape(-1, 1))))\n",
        "beta_hat = np.dot(np.linalg.inv(np.dot(X_diseno.T, X_diseno)), np.dot(X_diseno.T, Y))\n",
        "\n",
        "print(f\"Coeficientes beta usados: {beta_hat}\")\n",
        "\n",
        "# a) Calcular los valores predichos Y_hat\n",
        "Y_hat = np.dot(X_diseno, beta_hat)\n",
        "\n",
        "print(\"\\na) Valores predichos (Y_hat):\")\n",
        "print(Y_hat)\n",
        "\n",
        "# b) Calcular los residuos (e_i)\n",
        "residuos = Y - Y_hat\n",
        "\n",
        "print(\"\\nb) Residuos (Y - Y_hat):\")\n",
        "print(residuos)\n",
        "\n",
        "# c) Suma de los residuos\n",
        "suma_residuos = np.sum(residuos)\n",
        "print(\"\\nc) Suma de los residuos:\")\n",
        "print(f\"Suma total de residuos: {suma_residuos:.4f}\")\n",
        "\n",
        "print(\"\\nInterpretación de la suma de residuos:\")\n",
        "print(\"En un modelo OLS bien ajustado (que incluye un intercepto), esperamos que la suma de los residuos sea muy cercana a cero o exactamente cero (debido a la forma en que OLS minimiza la suma de los cuadrados). Un valor pequeño, como el obtenido (-0.0000), indica que el modelo está bien ajustado según el principio OLS.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95ddeb77"
      },
      "source": [
        "### **Ejercicio 15: Cálculo del R²**Utilizando los valores $Y$ observados y los valores $\\hat{Y}$ predichos del Ejercicio 14, así como la media de $Y$:a) Calcula la Suma Total de Cuadrados ($SS_{total}$).b) Calcula la Suma de Cuadrados de la Regresión ($SS_{regresión}$).c) Calcula la Suma de Cuadrados Residual ($SS_{residual}$).d) Finalmente, calcula el coeficiente de determinación R².e) Interpreta el valor de R² obtenido para este modelo.**Respuesta (con Python y NumPy):**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c76fd49d"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Recuperamos Y, Y_hat y la media de Y del Ejercicio 14\n",
        "# Si este código se ejecuta de forma independiente, tendrías que definirlos de nuevo:\n",
        "# X_original = np.array([1, 2, 3, 4, 5])\n",
        "# Y = np.array([2, 3.5, 4.5, 5, 6])\n",
        "# X_diseno = np.hstack((np.ones((len(X_original), 1)), X_original.reshape(-1, 1))))\n",
        "# beta_hat = np.dot(np.linalg.inv(np.dot(X_diseno.T, X_diseno)), np.dot(X_diseno.T, Y))\n",
        "# Y_hat = np.dot(X_diseno, beta_hat)\n",
        "\n",
        "# Para asegurar la continuidad, re-calculamos Y y Y_hat\n",
        "X_original = np.array([1, 2, 3, 4, 5])\n",
        "Y = np.array([2, 3.5, 4.5, 5, 6])\n",
        "X_diseno = np.hstack((np.ones((len(X_original), 1)), X_original.reshape(-1, 1))))\n",
        "beta_hat = np.dot(np.linalg.inv(np.dot(X_diseno.T, X_diseno)), np.dot(X_diseno.T, Y))\n",
        "Y_hat = np.dot(X_diseno, beta_hat)\n",
        "\n",
        "media_Y = np.mean(Y)\n",
        "print(f\"Valores Y observados: {Y}\")\n",
        "print(f\"Valores Y predichos: {Y_hat}\")\n",
        "print(f\"Media de Y: {media_Y:.4f}\")\n",
        "\n",
        "# a) Calcular Suma Total de Cuadrados (SS_total)\n",
        "SS_total = np.sum((Y - media_Y)**2)\n",
        "print(f\"\\na) Suma Total de Cuadrados (SS_total): {SS_total:.4f}\")\n",
        "\n",
        "# b) Calcular Suma de Cuadrados de la Regresión (SS_regresión)\n",
        "SS_regresion = np.sum((Y_hat - media_Y)**2)\n",
        "print(f\"\\nb) Suma de Cuadrados de la Regresión (SS_regresión): {SS_regresion:.4f}\")\n",
        "\n",
        "# c) Calcular Suma de Cuadrados Residual (SS_residual)\n",
        "SS_residual = np.sum((Y - Y_hat)**2)\n",
        "print(f\"\\nc) Suma de Cuadrados Residual (SS_residual): {SS_residual:.4f}\")\n",
        "\n",
        "# Verificar la relación: SS_total = SS_regresión + SS_residual\n",
        "print(f\"Verificación: SS_regresión + SS_residual = {SS_regresion + SS_residual:.4f} (debería ser igual a SS_total)\")\n",
        "\n",
        "# d) Calcular el coeficiente de determinación R²\n",
        "R2 = SS_regresion / SS_total\n",
        "# También se puede calcular como R2 = 1 - (SS_residual / SS_total)\n",
        "# R2_alternativo = 1 - (SS_residual / SS_total)\n",
        "\n",
        "print(f\"\\nd) Coeficiente de determinación R²: {R2:.4f}\")\n",
        "\n",
        "# e) Interpretación del valor de R²\n",
        "print(\"\\ne) Interpretación del R²:\")\n",
        "print(f\"El R² obtenido es {R2:.4f}, lo que significa que aproximadamente el {R2*100:.2f}% de la varianza en la variable dependiente Y (los valores observados) es explicada por la variable independiente X (mediante el modelo de regresión lineal). Este es un valor muy alto y cercano a 1, lo que indica que el modelo tiene un excelente ajuste a los datos y X es un muy buen predictor de Y.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}